# Brest-Cancer-Detection
### 1. Introduction
这次的数据集既包括文本又包括图片，我们要根据这些数据对乳腺癌病人的分子亚型进行分类，共有四类。

### 2. Method
主要思路： 分类以图片数据为主，由于每个病人的病理图片数量不一，单凭图片可能存在分不了类的情况。在此种情况下，我们引入文本信息进行辅助分类。

图片处理方法：CNN

文本处理方法：决策树

我们采用了两种网络结构训练图片，VGG16和ResNet18。batch_size大小设置为16，跑了20个epoch。对于VGG16，20个epoch结束后，acc不到0.5。而对于ResNet18，20个epoch之, acc可以达到0.97。在test阶段，将采用ResNet18 model。

对每个病人的图片进行分类后，属于同一个病人的图片可能有不同label，将出现次数最多的label作为此病人的label。如果各label数量都相等，则使用决策树处理文本信息辅助分类。

### 3. Result
比赛用户名：duby

比赛分数：0.32383 （仅使用决策树，分数为0.48294）

### 4. Procedure
1. 数据准备。按照label把训练集中的图片放入各自分类的文件夹内。（prepare.ipynb)

2. 图片训练。使用ResNet18对数据进行训练。(train.py)(这部分代码参考了"tslgithub"的代码，见reference）

3. 图片测试。对test文件夹下的文件进行分类。(predict.py)(这部分代码在"tslgithub"的代码的基础上进行修改）

4. 找出未能分类的病人id，进行决策树分类。(decision_tree.ipynb)

### 5. 心得体会

1. 分类精度不高，可能有两方面的原因。一是图片训练模型选择的不好，最开始想构造三元损失函数用弱监督学习来训练图片，但是代码总是调试不成功，加上弱监督学习的训练时间过长，放弃此种方法。 二是没有把文本信息和图片信息融合到一起进行分类，这类问题以前没有见过，不知有什么样的融合方法。用图片进行分类后，只有三名测试病人没有分类成功，如果想要提高精度，应在更多的数据上使用病人文本信息。

2. 数据处理方面，尤其是读入和写入数据这块费了很多时间。调整格式非常不熟练，于是借助了excel、记事本手动去调整数据。

（决策树部分暂时还没有写完上传，目前比赛分数只基于图片信息，会在13号把决策树部分补完）

13号更新：单独使用决策树，分数为0.48294，结果好于使用CNN分类图片。可能得原因有图片特征不明显，清晰度较差，所以导致CNN分类结果差。

### 6. Reference

https://github.com/tslgithub/image_class



